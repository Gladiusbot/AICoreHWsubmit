{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.复习课上内容， 阅读相应论文。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 回答以下理论题目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 1.  What is autoencoder?\n",
    "* 将输入数据压缩并产生出可被decoder解码的输出结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 2. What are the differences between greedy search and beam search?\n",
    "* greedy search: 每一步都把概率最高的输出作为输出结果\n",
    "* beam search: 在概率最高的几个输出中随机选取作为输出结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 3. What is the intuition of attention mechanism?\n",
    "* 在encoding的时候计算单词在句子中的的重要程度，并用于decoding。为模型提供长期记忆的能力，加快训练速度并提高准确度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 4. What is the disadvantage of word embedding introduced in previous lectures ?\n",
    "* 无法处理未知词汇\n",
    "* 以单词为单位处理,难以将学习到的词根等更低维度的信息复用\n",
    "* 更换语言需要新的嵌入矩阵\n",
    "* 无法被用于初始化目前最新发展出来的的模型架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 5. Briefly describe what is self-attention and what is multi-head attention?\n",
    "* Self-Attention利用了Attention机制，计算每个单词与其他所有单词之间的关联，计算单词之间的Attention score。利用这些Attention score就可以得到一个加权的表示，然后再放到一个前馈神经网络中得到新的表示，从而对上下文的信息加以利用。\n",
    "* Multi-head Attention其实就是多个Self-Attention结构的结合，每个head学习到在不同表示空间中的特征，每个head学习到的Attention侧重点可能略有不同，这样给了模型更大的容量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 中英文自动翻译模型的构建（使用encoder-decoder模型）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.geeksforgeeks.org/wp-content/uploads/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 [中英文翻译数据集下载](http://www.manythings.org/anki/)\n",
    "找到Chinese (Mandarin) - English cmn-eng.zip (22075条中英文翻译)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2  数据处理：encoder的输入，decoder的输入与输出\n",
    "1，句子转换为one-hot编码     \n",
    "2，LSTM需要的三维输入[n_samples, timestamp, one-hot feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "N_UNITS = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 50\n",
    "NUM_SAMPLES = 10000\n",
    "\n",
    "\n",
    "data_path = 'cmn.txt'\n",
    "df = pd.read_table(data_path,header=None).iloc[:NUM_SAMPLES,:,]\n",
    "df.columns=['inputs', 'targets', 'others']\n",
    "\n",
    "df['targets'] = df['targets'].apply(lambda x: '\\t'+x+'\\n')\n",
    "\n",
    "input_texts = df.inputs.values.tolist()\n",
    "target_texts = df.targets.values.tolist()\n",
    "\n",
    "input_characters = sorted(list(set(df.inputs.unique().sum())))\n",
    "target_characters = sorted(list(set(df.targets.unique().sum())))\n",
    "\n",
    "INUPT_LENGTH = max([len(i) for i in input_texts])\n",
    "OUTPUT_LENGTH = max([len(i) for i in target_texts])\n",
    "INPUT_FEATURE_LENGTH = len(input_characters)\n",
    "OUTPUT_FEATURE_LENGTH = len(target_characters)\n",
    "\n",
    "encoder_input = np.zeros((NUM_SAMPLES, INUPT_LENGTH, INPUT_FEATURE_LENGTH))\n",
    "decoder_input = np.zeros((NUM_SAMPLES, OUTPUT_LENGTH, OUTPUT_FEATURE_LENGTH))\n",
    "decoder_output = np.zeros((NUM_SAMPLES, OUTPUT_LENGTH, OUTPUT_FEATURE_LENGTH))\n",
    "\n",
    "input_dict = {char:index for index,char in enumerate(input_characters)}\n",
    "input_dict_reverse = {index:char for index,char in enumerate(input_characters)}\n",
    "target_dict = {char:index for index,char in enumerate(target_characters)}\n",
    "target_dict_reverse = {index:char for index,char in enumerate(target_characters)}\n",
    "\n",
    "for seq_index,seq in enumerate(input_texts):\n",
    "    for char_index, char in enumerate(seq):\n",
    "        encoder_input[seq_index, char_index, input_dict[char]] = 1\n",
    "\n",
    "for seq_index,seq in enumerate(target_texts):\n",
    "    for char_index,char in enumerate(seq):\n",
    "        decoder_input[seq_index,char_index, target_dict[char]] = 1.0\n",
    "        if char_index > 0:\n",
    "            decoder_output[seq_index,char_index-1, target_dict[char]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 encoder-decoder模型的搭建\n",
    "1，模型训练    \n",
    "2，模型推理     \n",
    "3，模型预测，展示结果   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_input, n_output, n_units):\n",
    "    # encoder\n",
    "    encoder_input = Input(shape=(None, n_input))\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    _,encoder_h, encoder_c = encoder(encoder_input)\n",
    "    encoder_state = [encoder_h, encoder_c]\n",
    "    \n",
    "    \n",
    "    decoder_input = Input(shape=(None, n_output))\n",
    "    decoder = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_output, _, _ = decoder(decoder_input,\n",
    "                                   initial_state=encoder_state)\n",
    "    decoder_dense = Dense(n_output, activation='softmax')\n",
    "    decoder_output = decoder_dense(decoder_output)\n",
    "    \n",
    "    model = Model([encoder_input, decoder_input], decoder_output)\n",
    "    \n",
    "    encoder_infer = Model(encoder_input, encoder_state)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))    \n",
    "    decoder_state_input = [decoder_state_input_h, decoder_state_input_c] \n",
    "    \n",
    "    decoder_infer_output, decoder_infer_state_h, decoder_infer_state_c = decoder(decoder_input,\n",
    "                                                                                 initial_state=decoder_state_input)\n",
    "    decoder_infer_state = [decoder_infer_state_h, decoder_infer_state_c]\n",
    "    decoder_infer_output = decoder_dense(decoder_infer_output)\n",
    "    decoder_infer = Model([decoder_input] + decoder_state_input,\n",
    "                          [decoder_infer_output] + decoder_infer_state)\n",
    "    \n",
    "    return model, encoder_infer, decoder_infer\n",
    "\n",
    "\n",
    "def predict_chinese(source,encoder_inference, decoder_inference, n_steps, features):\n",
    "    state = encoder_inference.predict(source)\n",
    "    predict_seq = np.zeros((1,1,features))\n",
    "    predict_seq[0,0,target_dict['\\t']] = 1\n",
    "    output = ''\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        yhat,h,c = decoder_inference.predict([predict_seq]+state)\n",
    "        char_index = np.argmax(yhat[0,-1,:])\n",
    "        char = target_dict_reverse[char_index]\n",
    "        output += char\n",
    "        state = [h,c]\n",
    "        predict_seq = np.zeros((1,1,features))\n",
    "        predict_seq[0,0,char_index] = 1\n",
    "        if char == '\\n':\n",
    "            break\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 70s 9ms/sample - loss: 1.9381 - val_loss: 2.4564\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 66s 8ms/sample - loss: 1.8048 - val_loss: 2.3582\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 66s 8ms/sample - loss: 1.7066 - val_loss: 2.2845\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 64s 8ms/sample - loss: 1.6219 - val_loss: 2.2021\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 1.5431 - val_loss: 2.1143\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 1.4685 - val_loss: 2.1078\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 63s 8ms/sample - loss: 1.4048 - val_loss: 2.0030\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 1.3468 - val_loss: 1.9514\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 1.2932 - val_loss: 1.9247\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 63s 8ms/sample - loss: 1.2452 - val_loss: 1.8853\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 72s 9ms/sample - loss: 1.2029 - val_loss: 1.8551\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 67s 8ms/sample - loss: 1.1645 - val_loss: 1.8396\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 77s 10ms/sample - loss: 1.1285 - val_loss: 1.8185\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 64s 8ms/sample - loss: 1.0944 - val_loss: 1.8151\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 64s 8ms/sample - loss: 1.0618 - val_loss: 1.8133\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 65s 8ms/sample - loss: 1.0308 - val_loss: 1.7900\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 65s 8ms/sample - loss: 1.0020 - val_loss: 1.7786\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 64s 8ms/sample - loss: 0.9742 - val_loss: 1.7747\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 63s 8ms/sample - loss: 0.9478 - val_loss: 1.7571\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 64s 8ms/sample - loss: 0.9207 - val_loss: 1.7551\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 65s 8ms/sample - loss: 0.8960 - val_loss: 1.7577\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 67s 8ms/sample - loss: 0.8720 - val_loss: 1.7543\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 65s 8ms/sample - loss: 0.8486 - val_loss: 1.7550\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 63s 8ms/sample - loss: 0.8252 - val_loss: 1.7609\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 63s 8ms/sample - loss: 0.8025 - val_loss: 1.7613\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 64s 8ms/sample - loss: 0.7813 - val_loss: 1.7591\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 63s 8ms/sample - loss: 0.7606 - val_loss: 1.7527\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 64s 8ms/sample - loss: 0.7397 - val_loss: 1.7513\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 65s 8ms/sample - loss: 0.7208 - val_loss: 1.7591\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 64s 8ms/sample - loss: 0.7008 - val_loss: 1.7596\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 65s 8ms/sample - loss: 0.6815 - val_loss: 1.7605\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 64s 8ms/sample - loss: 0.6634 - val_loss: 1.7585\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 63s 8ms/sample - loss: 0.6455 - val_loss: 1.7721\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 0.6271 - val_loss: 1.7751\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 0.6109 - val_loss: 1.7831\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 63s 8ms/sample - loss: 0.5945 - val_loss: 1.7960\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 0.5780 - val_loss: 1.8000\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 61s 8ms/sample - loss: 0.5625 - val_loss: 1.8004\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 61s 8ms/sample - loss: 0.5464 - val_loss: 1.8033\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 61s 8ms/sample - loss: 0.5316 - val_loss: 1.8060\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 65s 8ms/sample - loss: 0.5165 - val_loss: 1.8186\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 63s 8ms/sample - loss: 0.5028 - val_loss: 1.8149\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 61s 8ms/sample - loss: 0.4888 - val_loss: 1.8333\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 0.4763 - val_loss: 1.8348\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 0.4612 - val_loss: 1.8379\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 62s 8ms/sample - loss: 0.4498 - val_loss: 1.8557\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 61s 8ms/sample - loss: 0.4377 - val_loss: 1.8640\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 61s 8ms/sample - loss: 0.4267 - val_loss: 1.8647\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 63s 8ms/sample - loss: 0.4138 - val_loss: 1.8706\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 64s 8ms/sample - loss: 0.4028 - val_loss: 1.8891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20992dc4c50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train, encoder_infer, decoder_infer = create_model(\n",
    "    INPUT_FEATURE_LENGTH,\n",
    "    OUTPUT_FEATURE_LENGTH,\n",
    "    N_UNITS)\n",
    "\n",
    "model_train.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "validation_split = 0.2\n",
    "model_train.fit([encoder_input,decoder_input],\n",
    "    decoder_output,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCH,\n",
    "    validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop grumbling.\n",
      "停止大声不会说。\n",
      "\n",
      "Stop resisting!\n",
      "停止吧。\n",
      "\n",
      "Summer is over.\n",
      "夏天过去了。\n",
      "\n",
      "Take your time.\n",
      "你可以慢慢来。\n",
      "\n",
      "Take your time.\n",
      "你可以慢慢来。\n",
      "\n",
      "That was wrong.\n",
      "那是不喜欢的。\n",
      "\n",
      "That's a shame.\n",
      "那是一個正確的。\n",
      "\n",
      "That's logical.\n",
      "那是一個好的計劃。\n",
      "\n",
      "That's my coat.\n",
      "那是我的。\n",
      "\n",
      "That's perfect.\n",
      "那是一個正常。\n",
      "\n",
      "That's too bad.\n",
      "那不太好。\n",
      "\n",
      "That's too bad.\n",
      "那不太好。\n",
      "\n",
      "That's too bad.\n",
      "那不太好。\n",
      "\n",
      "The birds sang.\n",
      "这个男孩子。\n",
      "\n",
      "The flag is up.\n",
      "这个男孩子在吃面包。\n",
      "\n",
      "The phone rang.\n",
      "这个男孩子吃面包。\n",
      "\n",
      "Their eyes met.\n",
      "那些狗都很大。\n",
      "\n",
      "These are pens.\n",
      "這些是筆。\n",
      "\n",
      "They hated Tom.\n",
      "他们没看。\n",
      "\n",
      "They have jobs.\n",
      "他们有孩子。\n",
      "\n",
      "They let me go.\n",
      "他们亲吻了。\n",
      "\n",
      "They love that.\n",
      "他们没看。\n",
      "\n",
      "They trust Tom.\n",
      "他們會出敗。\n",
      "\n",
      "They want more.\n",
      "他们不喜欢我。\n",
      "\n",
      "They want this.\n",
      "他们没看。\n",
      "\n",
      "They were good.\n",
      "他们不喜欢我。\n",
      "\n",
      "This is a book.\n",
      "这是一个好。\n",
      "\n",
      "This is my bag.\n",
      "这是我的自行车。\n",
      "\n",
      "Tom can change.\n",
      "汤姆不傻。\n",
      "\n",
      "Tom can't swim.\n",
      "汤姆不会游泳。\n",
      "\n",
      "Tom has a plan.\n",
      "汤姆没有狗。\n",
      "\n",
      "Tom is a rabbi.\n",
      "汤姆是个骗子。\n",
      "\n",
      "Tom is no fool.\n",
      "汤姆不傻。\n",
      "\n",
      "Tom isn't dumb.\n",
      "汤姆不傻。\n",
      "\n",
      "Tom looks pale.\n",
      "汤姆走了。\n",
      "\n",
      "Tom loves dogs.\n",
      "汤姆走了。\n",
      "\n",
      "Tom turned red.\n",
      "汤姆睡着了。\n",
      "\n",
      "Tom walked out.\n",
      "湯姆會等。\n",
      "\n",
      "Tom was crying.\n",
      "汤姆不傻。\n",
      "\n",
      "Tom won't stop.\n",
      "汤姆不会游泳。\n",
      "\n",
      "Tom's fearless.\n",
      "汤姆很抱。\n",
      "\n",
      "Tom's laughing.\n",
      "汤姆很傻。\n",
      "\n",
      "Tom's thrilled.\n",
      "汤姆很傻。\n",
      "\n",
      "Turn on the TV.\n",
      "把电视给我们机会儿。\n",
      "\n",
      "Turn up the TV.\n",
      "把电视声音调大点儿。\n",
      "\n",
      "Was Tom asleep?\n",
      "汤姆是个的男人。\n",
      "\n",
      "Wash your feet.\n",
      "洗你的脚。\n",
      "\n",
      "Wash your feet.\n",
      "洗你的脚。\n",
      "\n",
      "Watch yourself.\n",
      "在这里着。\n",
      "\n",
      "We forgive you.\n",
      "我們是你的。\n",
      "\n",
      "We knew no one.\n",
      "我们知道。\n",
      "\n",
      "We need a hero.\n",
      "我们需要一条。\n",
      "\n",
      "We study music.\n",
      "我們必須走著。\n",
      "\n",
      "We were robbed.\n",
      "我們有時間。\n",
      "\n",
      "We'll continue.\n",
      "我们喜欢学习。\n",
      "\n",
      "We're a family.\n",
      "我们很高。\n",
      "\n",
      "We're not late.\n",
      "我们不同意。\n",
      "\n",
      "Well, let's go.\n",
      "好吧，我們走吧。\n",
      "\n",
      "Were you right?\n",
      "你是认真的吗？\n",
      "\n",
      "What about you?\n",
      "你們呢？\n",
      "\n",
      "What about you?\n",
      "你們呢？\n",
      "\n",
      "What do you do?\n",
      "你想要什麼?\n",
      "\n",
      "What's her job?\n",
      "我们要什么？\n",
      "\n",
      "Where do we go?\n",
      "我的書在哪？\n",
      "\n",
      "Where were you?\n",
      "你的東西在哪裡？\n",
      "\n",
      "Who's that guy?\n",
      "那是谁的？\n",
      "\n",
      "Who's that man?\n",
      "那是谁的？\n",
      "\n",
      "Why do you ask?\n",
      "你為什麼在這？\n",
      "\n",
      "Why is he here?\n",
      "为什么是对？\n",
      "\n",
      "Wipe your eyes.\n",
      "我们能回家。\n",
      "\n",
      "Yes, I know it.\n",
      "是的，我知道。\n",
      "\n",
      "Yes, of course.\n",
      "是的，沒有。\n",
      "\n",
      "You look bored.\n",
      "你看起来很困了。\n",
      "\n",
      "You look tense.\n",
      "你看起来很困了。\n",
      "\n",
      "You look tired.\n",
      "你看起来很困了。\n",
      "\n",
      "You look tired.\n",
      "你看起来很困了。\n",
      "\n",
      "You must do it.\n",
      "你看起来很困了。\n",
      "\n",
      "You'll love it.\n",
      "你的狗很漂亮。\n",
      "\n",
      "You're kidding!\n",
      "你是个好主主意。\n",
      "\n",
      "You're welcome.\n",
      "你的狗很多书。\n",
      "\n",
      "A man must work.\n",
      "我们不能游泳。\n",
      "\n",
      "Are you friends?\n",
      "你們是學生嗎？\n",
      "\n",
      "Are you kidding?\n",
      "你們是學生嗎？\n",
      "\n",
      "Are you over 18?\n",
      "你們是學生嗎？\n",
      "\n",
      "Are you serious?\n",
      "你們是學生嗎？\n",
      "\n",
      "Are you thirsty?\n",
      "你們是學生嗎？\n",
      "\n",
      "Balls are round.\n",
      "把它给给我。\n",
      "\n",
      "Be happy for me.\n",
      "把你放在桌子。\n",
      "\n",
      "Behave yourself.\n",
      "別著我的車。\n",
      "\n",
      "Black suits you.\n",
      "把你的车上去。\n",
      "\n",
      "Boil some water.\n",
      "給我一點水。\n",
      "\n",
      "Call the police!\n",
      "上帝存在。\n",
      "\n",
      "Call the police!\n",
      "上帝存在。\n",
      "\n",
      "Call the police.\n",
      "上帝存在。\n",
      "\n",
      "Can you find it?\n",
      "你能幫我嗎？\n",
      "\n",
      "Can you help me?\n",
      "你能幫我嗎？\n",
      "\n",
      "Can you help me?\n",
      "你能幫我嗎？\n",
      "\n",
      "Can you help us?\n",
      "你能幫我嗎？\n",
      "\n",
      "Clean your room.\n",
      "你在家里玩！\n",
      "\n",
      "Clean your room.\n",
      "你在家里玩！\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000,1100):\n",
    "    test = encoder_input[i:i+1,:,:] \n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    print(input_texts[i])\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://stickershop.line-scdn.net/stickershop/v1/product/3624648/LINEStorePC/main.png;compress=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
